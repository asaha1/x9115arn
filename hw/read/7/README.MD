<h1>i.	Reference to the paper: </h1>
Shahbaz, Muzammil, Phil McMinn, and Mark Stevenson. "Automatic generation of valid and invalid test data for string validation routines using web searches and regular expressions." Science of Computer Programming 97 (2015): 405-425.</br>

<h1>ii.	Most important keywords: </h1>
<b>ii1. Test Effectiveness: </b>Ratio between coverage percentages and number of test suits determine the effectiveness of tests.</br>
<b>ii2. Generation of string data: </b>The paper presents a new approach to generate string test data. The technique uses program identifiers to construct web search queries for regular expressions that validate the format of a string type (such as an email address).</br>
<b>iii3. Tokenisation: </b>A process of dividing a stream of texts into smaller elements known as tokens.</br>
<b>iii4. Routine validation: </b>A program that accepts a value as an input and returns true if it is accepted and false if it is rejected.</br>

<h1>iii. Brief Notes: </h1>
<b>iii1. Baseline Results: </b>The paper presents the results of an empirical study evaluating our approach [1]. The study was conducted on 24 string input validation routines collected from 10 open source projects. While dynamic symbolic execution and search-based testing approaches were only able to generate a very low number of values successfully, our approach generated values with an accuracy of 34% on average for the case of valid strings, and 99% on average for the case of invalid strings.</br>
<b>iii2. Motivational Statements: </b>There has been much work in the literature of late devoted to automated test input generation [4], however handling string input types remains a challenging task [5, 6]. This is due to the inherent complexity of real - world data that is naturally encoded as strings — e.g., dates of different formats, banking codes, registration numbers, etc. — which have very large input domains, and consequently, involve a huge search space for test data generation. In the paper web searches are made for strings that match the regular expressions, producing examples of test cases that are both valid and realistic. Following this, our technique mutates the regular expressions to drive the search for invalid strings, and the production of test inputs that should be rejected by the validation routine.</br>
<b>iii3. Informative Visualizations: </b></br>
Analysis of program errors exposed by valid values.</br>
<img src = "1. analysis.png"> </br>
Analysis of program errors exposed by invalidvalues averaged over 10 runs. The precision is given with the standard deviation to analyse the variation in all runs.</br>
<img src = "2 analysis.png"> </br>
<b>iii4.  Related work: </b>The input validation problem has been addressed in the classic software testing literature [2]. The earlier approaches assume the provision of grammars from which the inputs can be generated. Beizer [2] has presented approaches for syntax testing, also called grammar-based testing, where the syntax of the input is expressed in a formal specification, such as BNF and its equivalent graph. Then the valid inputs are generated by “covering” the graph. Invalid values can also be generated by employing heuristics such as interchanging terminal and non-terminal symbols (in the BNF), replacing numeric with alphabetic values and generating extra delimiters in the valid values — the so-called “error-condition” rules[3].</br>

<h1>iv.	Suggested Improvements:</h1> 
<b>iv1.</b> Test inputs are difficult release: Automatically generated test inputs are hard for humans who conduct tests to understand. </br>
<b>iv2.</b> Missing implementation testing inability: Some of the program implementation errors results from missing functionality. Single way to detect such errors is to test programs with invalid values.</br>
<b>iv3.</b> Low effectiveness of test: Where data types such as strings are concerned it is possible to build program structure without generation of any input.</br>

<h1>References:</h1>
[1] Shahbaz, Muzammil, Phil McMinn, and Mark Stevenson. "Automatic generation of valid and invalid test data for string validation routines using web searches and regular expressions." Science of Computer Programming 97 (2015): 405-425.</br>
[2] B. Beizer, Software Testing Techniques, International Thomson Computer Press, 1990.</br>
[3] J. Hayes, J. Offutt, Input validation analysis and testing, Empir. Softw. Eng. 11 (4) (2006) 493–522.</br>
[4] S. Anand, E. Burke, T. Y. Chen, J. Clark, M. B. Cohen, W. Grieskamp, M. Harman, M. J. Harrold, P. McMinn, An orchestrated survey on automated software test case generation, J. Syst. Softw. 86(8) (2013) 1978–2001.</br>
[5] P. Mc Minn, M. Shahbaz, M. Stevenson, Search-based test input generation for string data types using the results of web queries, in: Proceedings of the 5th International Conference on Software Testing, Verification and Validation (ICST), IEEE Computer Society, 2012, pp. 141–150.</br>
[6] M. Shahbaz, P. Mc Minn, M. Stevenson, Automated discovery of valid test strings from the web using dynamic regular expressions collation and natural language processing, in: Proceedings of the 12th International Conference on Quality Software (QSIC), 2012, pp. 79–88.</br>
